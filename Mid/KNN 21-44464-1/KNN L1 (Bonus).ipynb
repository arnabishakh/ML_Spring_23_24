{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!cp /content/drive/MyDrive/ML/data_utils.py /content\n","!cp /content/drive/MyDrive/ML/download.py /content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25i2Cas0Fi3a","executionInfo":{"status":"ok","timestamp":1712655851352,"user_tz":-360,"elapsed":3680,"user":{"displayName":"Arnab Bishakh","userId":"11979055915212200492"}},"outputId":"19ffcb7a-76cc-49b9-f528-4601fe48d466"},"id":"25i2Cas0Fi3a","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":2,"id":"0e762c63","metadata":{"id":"0e762c63","executionInfo":{"status":"ok","timestamp":1712655851352,"user_tz":-360,"elapsed":7,"user":{"displayName":"Arnab Bishakh","userId":"11979055915212200492"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import data_utils\n","import download\n","from tqdm import tqdm\n","\n","def download_data():\n","    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n","    download_dir = \"./data\"\n","    tqdm(download.maybe_download_and_extract(url,download_dir), desc='CIFAR10 Downloading')"]},{"cell_type":"code","execution_count":3,"id":"70f41df0","metadata":{"id":"70f41df0","executionInfo":{"status":"ok","timestamp":1712655851352,"user_tz":-360,"elapsed":6,"user":{"displayName":"Arnab Bishakh","userId":"11979055915212200492"}}},"outputs":[],"source":["  # Class to initialize and apply K-nearest neighbour classfier\n","class KNearestNeighbor(object):\n","    def __init__(self):\n","          pass\n","\n","    # Method to initialize classifier with training data\n","    def train(self, X, y):\n","        self.X_train = X\n","        self.y_train = y\n","\n","    # Method to predict labels of test examples using 'compute_distances' and 'predict_labels' methods.\n","    def predict(self, X, k=1, num_loops=0):\n","        if num_loops == 0:\n","            dists = self.compute_distances(X)\n","        else:\n","            raise ValueError('Invalid value %d for num_loops' % num_loops)\n","        return self.predict_labels(dists, k=k)\n","\n","    # Method to compute Manhattan distances from each text example to every training example\n","    # Compute Manhattan (L1) distances\n","    def compute_distances(self, X_test):\n","        num_test = X_test.shape[0]\n","        num_train = self.X_train.shape[0]\n","        dists = np.zeros((num_test, num_train))\n","        for i in range(num_test):\n","            for j in range(num_train):\n","                # Manhattan distance\n","                dists[i, j] = np.sum(np.abs(X_test[i, :] - self.X_train[j, :]))\n","        return dists\n","\n","    # Method to predict labels of test examples using chosen value of k given Euclidean distances obtained from 'compute_distances' method.\n","    def predict_labels(self, dists, k=1):\n","        num_test = dists.shape[0]\n","        y_pred = np.zeros(num_test)\n","        for i in range(num_test):\n","            # Get the indices of the k nearest neighbors\n","            closest_y_indices = np.argsort(dists[i])[:k]\n","            closest_y = self.y_train[closest_y_indices]\n","\n","            # Predict the label of each test point: select the most common label\n","            y_pred[i] = np.argmax(np.bincount(closest_y))\n","        return y_pred\n","\n","    def visualize_data(X_train, y_train):\n","      classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","      num_classes = len(classes)\n","      samples_per_class = 7\n","      for y, cls in enumerate(classes):\n","          idxs = np.flatnonzero(y_train == y)\n","          idxs = np.random.choice(idxs, samples_per_class, replace=False)\n","          for i, idx in enumerate(idxs):\n","              plt_idx = i * num_classes + y + 1\n","              plt.subplot(samples_per_class, num_classes, plt_idx)\n","              plt.imshow(X_train[idx].astype('uint8'))\n","              plt.axis('off')\n","              if i == 0:\n","                  plt.title(cls)\n","      plt.show()"]},{"cell_type":"code","execution_count":null,"id":"beaf77e9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"beaf77e9","outputId":"0c37f61f-effb-4c90-eff6-2718746243da"},"outputs":[{"output_type":"stream","name":"stdout","text":["- Download progress: 100.0%\n","Download finished. Extracting files.\n","Done.\n"]},{"output_type":"stream","name":"stderr","text":["CIFAR10 Downloading: 0it [00:00, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training data shape:  (50000, 32, 32, 3)\n","Training labels shape:  (50000,)\n","Test data shape:  (10000, 32, 32, 3)\n","Test labels shape:  (10000,)\n","(10000, 3072) (1000, 3072)\n","Got 310 / 1000 correct with k=5 => accuracy: 0.310000\n"]},{"output_type":"stream","name":"stderr","text":["k choices:   0%|          | 0/10 [00:00<?, ?it/s]\n","  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n"," 20%|██        | 1/5 [03:41<14:45, 221.45s/it]\u001b[A\n"," 40%|████      | 2/5 [07:23<11:05, 221.81s/it]\u001b[A\n"," 60%|██████    | 3/5 [11:04<07:22, 221.42s/it]\u001b[A\n"," 80%|████████  | 4/5 [14:46<03:41, 221.82s/it]\u001b[A\n","100%|██████████| 5/5 [18:31<00:00, 222.27s/it]\n","k choices:  10%|█         | 1/10 [18:31<2:46:42, 1111.35s/it]\n","  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n"," 20%|██        | 1/5 [03:44<14:59, 224.95s/it]\u001b[A\n"," 40%|████      | 2/5 [07:26<11:08, 222.92s/it]\u001b[A\n"," 60%|██████    | 3/5 [11:09<07:25, 222.88s/it]\u001b[A\n"," 80%|████████  | 4/5 [14:51<03:42, 222.44s/it]\u001b[A\n","100%|██████████| 5/5 [18:31<00:00, 222.31s/it]\n","k choices:  20%|██        | 2/10 [37:02<2:28:11, 1111.47s/it]\n","  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n"," 20%|██        | 1/5 [03:40<14:43, 220.88s/it]\u001b[A\n"," 40%|████      | 2/5 [07:22<11:04, 221.38s/it]\u001b[A\n"," 60%|██████    | 3/5 [11:04<07:23, 221.61s/it]\u001b[A\n"," 80%|████████  | 4/5 [14:44<03:41, 221.03s/it]\u001b[A\n","100%|██████████| 5/5 [18:26<00:00, 221.24s/it]\n","k choices:  30%|███       | 3/10 [55:29<2:09:23, 1109.06s/it]\n","  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n"," 20%|██        | 1/5 [03:42<14:51, 222.90s/it]\u001b[A\n"," 40%|████      | 2/5 [07:25<11:07, 222.55s/it]\u001b[A\n"," 60%|██████    | 3/5 [11:07<07:24, 222.27s/it]\u001b[A\n"," 80%|████████  | 4/5 [14:47<03:41, 221.65s/it]\u001b[A\n","100%|██████████| 5/5 [18:29<00:00, 221.88s/it]\n","k choices:  40%|████      | 4/10 [1:13:58<1:50:55, 1109.21s/it]\n","  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n"," 20%|██        | 1/5 [03:41<14:46, 221.63s/it]\u001b[A\n"," 40%|████      | 2/5 [07:22<11:03, 221.11s/it]\u001b[A\n"," 60%|██████    | 3/5 [11:03<07:22, 221.08s/it]\u001b[A\n"," 80%|████████  | 4/5 [14:44<03:41, 221.27s/it]\u001b[A\n","100%|██████████| 5/5 [18:25<00:00, 221.10s/it]\n","k choices:  50%|█████     | 5/10 [1:32:24<1:32:19, 1107.87s/it]\n","  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n"," 20%|██        | 1/5 [03:41<14:45, 221.39s/it]\u001b[A\n"," 40%|████      | 2/5 [07:20<10:59, 219.97s/it]\u001b[A\n"," 60%|██████    | 3/5 [11:02<07:22, 221.11s/it]\u001b[A\n"," 80%|████████  | 4/5 [14:43<03:40, 220.82s/it]\u001b[A\n","100%|██████████| 5/5 [18:24<00:00, 220.94s/it]\n","k choices:  60%|██████    | 6/10 [1:50:48<1:13:47, 1106.80s/it]\n","  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n"," 20%|██        | 1/5 [03:38<14:33, 218.36s/it]\u001b[A\n"," 40%|████      | 2/5 [07:18<10:58, 219.63s/it]\u001b[A\n"," 60%|██████    | 3/5 [10:58<07:19, 219.64s/it]\u001b[A\n"," 80%|████████  | 4/5 [14:39<03:40, 220.25s/it]\u001b[A\n","100%|██████████| 5/5 [18:18<00:00, 219.67s/it]\n","k choices:  70%|███████   | 7/10 [2:09:07<55:12, 1104.04s/it]  \n","  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n"," 20%|██        | 1/5 [03:47<15:11, 227.92s/it]\u001b[A\n"," 40%|████      | 2/5 [07:27<11:09, 223.21s/it]\u001b[A\n"," 60%|██████    | 3/5 [11:09<07:24, 222.35s/it]\u001b[A\n"," 80%|████████  | 4/5 [14:48<03:41, 221.01s/it]\u001b[A\n","100%|██████████| 5/5 [18:29<00:00, 221.80s/it]\n","k choices:  80%|████████  | 8/10 [2:27:36<36:51, 1105.63s/it]\n","  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n"," 20%|██        | 1/5 [03:40<14:40, 220.21s/it]\u001b[A\n"," 40%|████      | 2/5 [07:21<11:02, 220.77s/it]\u001b[A\n"," 60%|██████    | 3/5 [11:00<07:19, 219.80s/it]\u001b[A\n"," 80%|████████  | 4/5 [14:40<03:40, 220.10s/it]\u001b[A\n","100%|██████████| 5/5 [18:19<00:00, 219.91s/it]\n","k choices:  90%|█████████ | 9/10 [2:45:55<18:23, 1103.73s/it]\n","  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n"," 20%|██        | 1/5 [03:41<14:46, 221.57s/it]\u001b[A\n"," 40%|████      | 2/5 [07:27<11:11, 223.88s/it]\u001b[A\n"," 60%|██████    | 3/5 [11:18<07:34, 227.27s/it]\u001b[A\n"," 80%|████████  | 4/5 [15:11<03:49, 229.70s/it]\u001b[A\n","100%|██████████| 5/5 [18:56<00:00, 227.23s/it]\n","k choices: 100%|██████████| 10/10 [3:04:51<00:00, 1109.19s/it]\n"]},{"output_type":"stream","name":"stdout","text":["k = 1, accuracy = 0.320000\n","k = 1, accuracy = 0.322000\n","k = 1, accuracy = 0.297000\n","k = 1, accuracy = 0.293000\n","k = 1, accuracy = 0.297000\n","k = 3, accuracy = 0.315500\n","k = 3, accuracy = 0.295500\n","k = 3, accuracy = 0.300000\n","k = 3, accuracy = 0.290000\n","k = 3, accuracy = 0.286500\n","k = 5, accuracy = 0.324500\n","k = 5, accuracy = 0.317000\n","k = 5, accuracy = 0.323500\n","k = 5, accuracy = 0.290000\n","k = 5, accuracy = 0.301000\n","k = 8, accuracy = 0.324000\n","k = 8, accuracy = 0.326000\n","k = 8, accuracy = 0.321500\n","k = 8, accuracy = 0.300500\n","k = 8, accuracy = 0.314000\n","k = 10, accuracy = 0.329500\n","k = 10, accuracy = 0.323000\n","k = 10, accuracy = 0.325500\n","k = 10, accuracy = 0.291000\n","k = 10, accuracy = 0.313000\n","k = 12, accuracy = 0.327000\n","k = 12, accuracy = 0.316500\n","k = 12, accuracy = 0.324000\n","k = 12, accuracy = 0.289000\n","k = 12, accuracy = 0.307000\n","k = 15, accuracy = 0.323500\n","k = 15, accuracy = 0.331000\n","k = 15, accuracy = 0.317500\n","k = 15, accuracy = 0.294500\n","k = 15, accuracy = 0.311000\n","k = 20, accuracy = 0.319000\n","k = 20, accuracy = 0.331000\n","k = 20, accuracy = 0.307000\n","k = 20, accuracy = 0.290500\n","k = 20, accuracy = 0.300500\n","k = 50, accuracy = 0.305000\n","k = 50, accuracy = 0.315500\n","k = 50, accuracy = 0.300500\n","k = 50, accuracy = 0.293000\n","k = 50, accuracy = 0.289500\n","k = 100, accuracy = 0.304500\n","k = 100, accuracy = 0.301000\n","k = 100, accuracy = 0.288500\n","k = 100, accuracy = 0.275000\n","k = 100, accuracy = 0.274000\n"]}],"source":["if __name__ == \"__main__\":\n","\n","    # Downloading CIFAR10 data\n","    download_data()\n","    cifar10_dir = r'./data/cifar-10-batches-py'\n","\n","    # Load training and testing data from CIFAR10 dataset\n","    X_train, y_train, X_test, y_test = data_utils.load_CIFAR10(cifar10_dir)\n","\n","    # Checking the size of the training and testing data\n","    print('Training data shape: ', X_train.shape)\n","    print('Training labels shape: ', y_train.shape)\n","    print('Test data shape: ', X_test.shape)\n","    print('Test labels shape: ', y_test.shape)\n","\n","    # Memory error prevention by subsampling data. We sample 10000 training examples and 1000 test examples.\n","    num_training = 10000\n","    mask = list(range(num_training))\n","    X_train = X_train[mask]\n","    y_train = y_train[mask]\n","\n","    num_test = 1000\n","    mask = list(range(num_test))\n","    X_test = X_test[mask]\n","    y_test = y_test[mask]\n","\n","    # Reshape data and place into rows. Flatten the training and test data so each row\n","    # consists of all pixels of an example\n","    X_train = X_train.reshape(X_train.shape[0], -1)\n","    X_test = X_test.reshape(X_test.shape[0], -1)\n","\n","    print(X_train.shape, X_test.shape)  # X_train should be (10000, 3072) and X_test should be (1000, 3072)\n","\n","\n","    # Initializing the classifier with training data\n","    classifier = KNearestNeighbor()\n","    classifier.train(X_train, y_train)  # Assuming X_train and y_train are defined earlier\n","\n","    # Computing distances from test examples to training examples\n","    dists = classifier.compute_distances(X_test)  # Assuming X_test is defined earlier\n","\n","    # Predicting labels for each test example in X_test using k=5\n","    y_test_pred = classifier.predict_labels(dists, k=5)\n","\n","    # Compute and print out the accuracy\n","    num_correct = np.sum(y_test_pred == y_test)  # Assuming y_test is defined earlier\n","    num_test = y_test.shape[0]  # Assuming y_test is an array of test labels\n","    accuracy = float(num_correct) / num_test\n","    print('Got %d / %d correct with k=5 => accuracy: %f' % (num_correct, num_test, accuracy))\n","\n","    # Prepare for 5-fold cross-validation\n","    num_folds = 5\n","    k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n","\n","    # Splitting the training data into 5 folds\n","    X_train_folds = np.array_split(X_train, num_folds)\n","    y_train_folds = np.array_split(y_train, num_folds)\n","\n","    # Dictionary to hold validation accuracies for different values of k\n","    k_to_accuracies = {}\n","\n","    for k in tqdm(k_choices, desc='k choices'):\n","        k_to_accuracies[k] = []\n","        for fold in tqdm(range(num_folds)):\n","            # Use 'fold' as the validation set and the other folds as the training set\n","            X_train_cv = np.concatenate([X_train_folds[i] for i in range(num_folds) if i != fold])\n","            y_train_cv = np.concatenate([y_train_folds[i] for i in range(num_folds) if i != fold])\n","            X_valid_cv = X_train_folds[fold]\n","            y_valid_cv = y_train_folds[fold]\n","\n","            # Train the classifier using the training folds\n","            classifier.train(X_train_cv, y_train_cv)\n","\n","            # Compute distances and predict labels for the validation fold\n","            dists_cv = classifier.compute_distances(X_valid_cv)\n","            y_valid_pred = classifier.predict_labels(dists_cv, k)\n","\n","            # Compute and store the accuracy for this fold\n","            num_correct_cv = np.sum(y_valid_pred == y_valid_cv)\n","            accuracy_cv = float(num_correct_cv) / len(y_valid_cv)\n","            k_to_accuracies[k].append(accuracy_cv)\n","\n","    # Print out the computed accuracies for each value of k\n","    for k in sorted(k_to_accuracies):\n","        for accuracy in k_to_accuracies[k]:\n","            print('k = %d, accuracy = %f' % (k, accuracy))\n","\n","\n","    for k in k_choices:\n","        k_to_accuracies[k] = []  # each key, k, should hold its list of 5 validation accuracies\n","\n","        # For each fold of cross validation\n","        for num_knn in range(num_folds):\n","            # 1) Split training data into validation fold and training folds\n","            X_train_folds_temp = X_train_folds[:]\n","            X_valid = X_train_folds_temp.pop(num_knn)\n","            X_train_temp = np.concatenate(X_train_folds_temp)\n","\n","            y_train_folds_temp = y_train_folds[:]\n","            y_valid = y_train_folds_temp.pop(num_knn)\n","            y_train_temp = np.concatenate(y_train_folds_temp)\n","\n","            # 2) Initialize classifier with training folds\n","            classifier.train(X_train_temp, y_train_temp)\n","\n","            # Compute distances between examples in validation fold and training folds\n","            dists = classifier.compute_distances(X_valid)\n","\n","            # 3) Use classifier to predict labels of validation fold for given k value\n","            y_test_pred = classifier.predict_labels(dists, k=k)\n","\n","            # Compute accuracy\n","            num_correct = np.sum(y_test_pred == y_valid)\n","            num_test = y_valid.shape[0]  # Number of examples in the validation fold\n","            accuracy = float(num_correct) / num_test\n","            k_to_accuracies[k].append(accuracy)\n","\n","    print(\"Printing our 5-fold accuracies for varying values of k:\")\n","    print()\n","    for k in sorted(k_to_accuracies):\n","        for accuracy in k_to_accuracies[k]:\n","            print('k = %d, accuracy = %f' % (k, accuracy))\n","\n","    # Print average accuracy for each k\n","    for k in sorted(k_to_accuracies):\n","        print('k = %d, avg. accuracy = %f' % (k, sum(k_to_accuracies[k])/num_folds))\n","\n","    # Visualizing the accuracies for different k values\n","    plt.figure(figsize=(10, 6))\n","    for k in k_choices:\n","        accuracies = k_to_accuracies[k]\n","        plt.scatter([k] * len(accuracies), accuracies)\n","\n","    plt.title('Cross-validation on k')\n","    plt.xlabel('k value')\n","    plt.ylabel('Validation accuracy')\n","    plt.plot()\n","\n","    # After populating k_to_accuracies with accuracies from cross-validation\n","    accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n","    # Error bars\n","    accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n","\n","    # Identifying the best k value based on cross-validation results\n","    best_k = k_choices[np.argmax(accuracies_mean)]\n","    print(\"Best k value:\", best_k)\n","\n","    # Initialize the classifier with the entire training data\n","    classifier.train(X_train, y_train)\n","\n","    # Compute distances between test examples and all training examples\n","    dists = classifier.compute_distances(X_test)\n","\n","    # Predict labels for test data using the best k\n","    y_test_pred = classifier.predict_labels(dists, k=best_k)\n","\n","    # Compute and display the accuracy for the best k on test data\n","    num_correct = np.sum(y_test_pred == y_test)\n","    accuracy = float(num_correct) / num_test\n","    print('Got %d / %d correct on test data => accuracy: %f' % (num_correct, num_test, accuracy))"]},{"cell_type":"code","execution_count":null,"id":"ab7c7cca","metadata":{"id":"ab7c7cca"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Tf_GPU_Accl","language":"python","name":"tensorflow"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}
